## 4th Study Paper List

Date | Paper | Presenter | Links
:---: | :---: | :---: | :---:
3/29 | Dueling Network Architectures for Deep Reinforcement Learning, Wang et al, 2015. | Jiyun Kim | [[paper]](https://arxiv.org/abs/1511.06581) [review]
3/29 | Sim-to-Real Leaning of All Common Bipedal Gaits via Periodic Reward Composition, J. Siekmann et al, 2020. | Hansol Kang | [[paper]](https://arxiv.org/abs/2011.01387) [review]
4/5 | Asynchronous Methods for Deep Reinforcement Learning, Mnih et al, 2016. | Jiwon Chong | [[paper]](https://arxiv.org/abs/1602.01783) [review]
4/5 | Deep Reinforcement Learning with Double Q-learning, Hasselt et al, 2015. | Soobin Park | [[paper]](https://arxiv.org/abs/1509.06461) [review]
4/12 | Adversarially Guided Actor-Critic, Y. Flet-Berliac et al, 2021. | Chris Ohk | [[paper]](https://arxiv.org/abs/2102.04376) [review]
4/12 | Hindsight Experience Replay, M. Andrychowicz et al, 2017. | Donggu Kang | [[paper]](https://arxiv.org/abs/1707.01495) [review]
4/19 | Addressing Function Approximation Error in Actor-Critic Methods, S. Fujimoto et al, 2018. | Junhyun Park | [[paper]](https://arxiv.org/abs/1802.09477) [review]
4/19 | Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments, R. Lowe et al, 2017. | Seungeon Baek | [[paper]](https://arxiv.org/abs/1706.02275) [review]
4/26 | Generating Text with Deep Reinforcement Learning, H. Guo et al, 2015. | Wonho Lee | [[paper]](https://arxiv.org/abs/1510.09202) [review]
4/26 | Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor, T. Haarnoja et al, 2018. | Soohan Kang | [[paper]](https://arxiv.org/abs/1801.01290) [review]
5/3 | Distributional Reinforcement Learning with Quantile Regression, W. Dabney et al, 2017. | Jiae Lee | [[paper]](https://arxiv.org/abs/1710.10044) [review]
5/3 | QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation, Kalashnikov et al, 2018. | Jihyeok Choi | [[paper]](https://arxiv.org/abs/1806.10293) [review]
5/10 | Randomized Ensembled Double Q-Learning: Learning Fast Without a Model, X. Chen et al, 2021. | Jungyeon Lee | [[paper]](https://arxiv.org/abs/2101.05982) [review]
5/10 | Human-Level Control through Deep Reinforcement Learning, Mnih et al. 2015. | Kangbeen Ko | [[paper]](https://www.nature.com/articles/nature14236?wm=book_wap_0005) [review]
5/17 | Proximal Policy Optimization Algorithms, J. Schulman et al, 2017. | Wonwoo Choi | [[paper]](https://arxiv.org/abs/1707.06347) [review]
5/17 | Continuous Control with Deep Reinforcement Learning, TP. Lillicrap et al, 2015. | Bongseok Kim | [[paper]](https://arxiv.org/abs/1509.02971) [review]
5/24 | Demand-Aware Career Path Recommendations: A Reinforcement Learning Approach, M. Kokkodis et al, 2020. | Minkyu Shin | [[paper]](https://pubsonline.informs.org/doi/pdf/10.1287/mnsc.2020.3727) [review]
5/24 | Deep Reinforcement Learning for Dialogue Generation, J. Li et al, 2016. | Daejin Jo | [[paper]](https://arxiv.org/abs/1606.01541) [review]

### Study Member

* [Chris Ohk](http://www.github.com/utilForever)
* [Jiyun Kim](http://www.github.com/Helia-17)
* [Hansol Kang](http://www.github.com/OnesoulKang)
* Jiwon Chong
* Soobin Park
* [Donggu Kang](http://www.github.com/HERIUN)
* [Junhyun Park](http://www.github.com/jundev1l2l)
* [Seungeon Baek](http://www.github.com/SeungeonBaek)
* [Wonho Lee](http://www.github.com/lee-wonho)
* Soohan Kang
* Jiae Lee
* [Jihyeok Choi](http://www.github.com/bluesaurus2)
* [Jungyeon Lee](http://www.github.com/curieuxjy)
* [Kangbeen Ko](http://www.github.com/KevinTheRainmaker)
* [Wonwoo Choi](http://www.github.com/deepwonwoo)
* Bongseok Kim
* Minkyu Shin
* [Daejin Jo](http://www.github.com/twidddj)